{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Parsing HTML\n",
    "Answer: No\n",
    "HTML is strictly hierarchical. Converting html text into an \"object oriented\" format would make more sense. Such a form is more adequat for parsing. Depending on the goal it might be beneficial to perform search via regular expressions in a second step. Of course it always depends on the use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['double_ocr.pdf', 'single_ocr.pdf']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir(\"scans\"))\n",
    "from difflib import SequenceMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_textract(filename):\n",
    "    import textract\n",
    "    return textract.process(filename).decode(\"utf-8\")\n",
    "\n",
    "def process_mymupdf(filename):\n",
    "    text = \"\"\n",
    "    import fitz\n",
    "    with fitz.open(filename) as doc:\n",
    "        for page in doc:\n",
    "            text += page.getText()\n",
    "    return text\n",
    "\n",
    "def process_pdftotext(filename):\n",
    "    import pdftotext\n",
    "    with open(filename, \"rb\") as f:\n",
    "        pdf = pdftotext.PDF(f)\n",
    "        pdf = (\"\\n\\n\".join(pdf))\n",
    "        return pdf\n",
    "\n",
    "def process_tika(filename):  # did not work out of the box\n",
    "    import tika\n",
    "    tika.initVM()\n",
    "    raw = tika.parser.from_file(filename)\n",
    "    return (raw['content'])\n",
    "\n",
    "fn_list = [process_mymupdf, process_textract, process_pdftotext]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"scans/single_ocr.pdf\"\n",
    "second_filename = \"scans/double_ocr.pdf\"\n",
    "results = []\n",
    "results_secondfile = []\n",
    "for fn in fn_list:\n",
    "    results.append(fn(filename))\n",
    "    results_secondfile.append(fn(second_filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### qualititative analysis\n",
    "after analysing the output of the three methods we arrived at the following conclusions:\n",
    "- tika has a lot of linebreaks in between names and adresses.\n",
    "- textextract is similar, but seems to have more problems with uncommon symbols which result in outputs like \"ItCharleg o;;eansnum \" \n",
    "- pdftotext works by far the best. The majority of line breaks resembles the actual document. Far easier to read.\n",
    "Names and adresses are usually on the same line connected by .... \n",
    "\n",
    "For the double_ocr.pdf file the first method also performs worst. Textextract results in more intuitive blocks of adresses. However pdftotext leads to the best overall results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## quantitative analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sequence matcher output shows that method 0 is significantly more similar to both 1 and 2 than 1 and 2 are to each other\n",
    "\n",
    "for the \"double_ocr.pdf\" file the ratios are relatively similar. There are no similarities to the single_ocr.pdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single ocr file\n",
      "0.4126882818483533\n",
      "0.22705626628171305\n",
      "0.4404858032727452\n",
      "\n",
      "double ocr file\n",
      "0.12592163035374038\n",
      "0.11796194775878749\n",
      "0.11129923649490464\n"
     ]
    }
   ],
   "source": [
    "print(\"single ocr file\")\n",
    "print(SequenceMatcher(None, results[0], results[1]).ratio())\n",
    "print(SequenceMatcher(None, results[1], results[2]).ratio())\n",
    "print(SequenceMatcher(None, results[0], results[2]).ratio())\n",
    "print()\n",
    "\n",
    "print(\"double ocr file\")\n",
    "print(SequenceMatcher(None, results_secondfile[0], results_secondfile[1]).ratio())\n",
    "print(SequenceMatcher(None, results_secondfile[1], results_secondfile[2]).ratio())\n",
    "print(SequenceMatcher(None, results_secondfile[0], results_secondfile[2]).ratio())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process_mymupdf 15876\n",
      "process_textract 15460\n",
      "process_pdftotext 44807\n"
     ]
    }
   ],
   "source": [
    "num_symbols = [len(result) for result in results]\n",
    "for fn, num in zip(fn_list, num_symbols):\n",
    "    print(fn.__name__, num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "counting the number of symbols for each method shows that the pdftotext method outputs ~3 x more symbols.\n",
    "However when removing multiple blank spaces it becomes the shortest output\n",
    "\n",
    "here the methods behave similar on both files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process_mymupdf 15796\n",
      "process_textract 15460\n",
      "process_pdftotext 14971\n"
     ]
    }
   ],
   "source": [
    "num_symbols_filtered = [len(result.replace(\"  \", \"\")) for result in results]\n",
    "for fn, num in zip(fn_list, num_symbols_filtered):\n",
    "    print(fn.__name__, num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems bad methods produce many linebreaks. Therefore a low number of linebreaks might be a useful indicator for higher accuracy.\n",
    "here the methods behave similar on both files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process_mymupdf 631\n",
      "process_textract 956\n",
      "process_pdftotext 160\n"
     ]
    }
   ],
   "source": [
    "num_linebreaks = [result.count(\"\\n\") for result in results]\n",
    "for fn, num in zip(fn_list, num_linebreaks):\n",
    "    print(fn.__name__, num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## summary\n",
    "pdftotext works best. The downside is the large number of multiple whitespaces. Therefore these are removed\n",
    "The methods behave similar on both files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"converted_single_ocr.txt\", \"w+\") as outfile:\n",
    "    outfile.write(results[2].replace(\"  \", \"\"))\n",
    "with open(\"converted_double_ocr.txt\", \"w+\") as outfile:\n",
    "    outfile.write(results_secondfile[2].replace(\"  \", \"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## exercise 3: why is pdf conversion hard?\n",
    "- pdf enables a large variety of layouts. Worse more any given layout of content can be achieved through many different ways. In plain text layouts are only represented in whitespaces, linebreaks and tabs. \n",
    "When trying to convert to plain text this layout information needs to be convert. As the layout info from pdfs is highly ambigous this is difficult.\n",
    "- even in between words that seem to be a single \"block\" of text, the conversion results in many blocks being seperated into small fragments. This indicates that within the pdf they are not a single block, even though they look as one. This makes decoding difficult\n",
    "- images and graphics overlapping with text is common in pdf and hard to decode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## exercise 4.1: Phone numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "phone_files = list(glob.iglob(\"phone_numbers/*.pdf\"))\n",
    "candidate = \"(0|\\+|Tel.{0,5})([\\s+\\–]{0,3}[1-9])([0-9\\-\\s\\–]{3,18})\"\n",
    "normalize_regex = \"[0-9]+\"\n",
    "plaintexts = []\n",
    "for file in phone_files:\n",
    "    plaintexts.append(\n",
    "        process_pdftotext(file).replace(\"  \",\"\").replace(\"\\n\\n\", \"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found  310 phone numbers\n",
      "found  461 phone numbers\n",
      "found  6 phone numbers\n",
      "found  3 phone numbers\n"
     ]
    }
   ],
   "source": [
    "total_matches = []\n",
    "for plaintext in plaintexts:\n",
    "    matches = re.findall(candidate, plaintext)\n",
    "    print(\"found \", len(matches), \"phone numbers\")\n",
    "    matches = [''.join(match) for match in matches]\n",
    "    matches = [re.sub(r\"[a-zA-Z+\\s\\n\\:\\.\\-\\–]*\", r\"\", match) for match in matches]\n",
    "    total_matches.extend(matches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"phone_numbers.txt\", \"w+\") as outfile:\n",
    "    for number in total_matches:\n",
    "        outfile.write(number + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
